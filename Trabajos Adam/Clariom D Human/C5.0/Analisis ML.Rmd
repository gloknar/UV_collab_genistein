---
title: "Análisis de microarrays _Clariom D Human_ en R - ML"
author: "Adam Casas"
date: 'Compilado: `r format(Sys.Date(), "%d de %B del %Y")`'
output: 
  html_document:
    df_print: paged
    highlight: kate
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r configuracion inicial, include=FALSE}
# Establecemos la configuración de los chunks
knitr::opts_chunk$set(echo = TRUE,
                      message = TRUE,
                      warning = FALSE,
                      tidy = F)

# Establecemos el directorio de trabajo de este informe
# knitr::opts_knit$set(root.dir = "C:/Users/Adam_/Desktop/microvesiculas - copia para trabajar/Resultados ClariomD_Human")


set.seed(1)
##################################################
#######        Encoded in UTF-8        ###########
##################################################
```

***

# Introducción

Vamos a hacer un análisis exploratorio en árboles de decisiones para ver qué genes son los más importantes a la hora de clasificar un microarray como control o como tratado con genisteína.

El análisis será exploratorio porque tenemos un tamaño muestral demasiado bajo como para aplicar técnicas avanzadas de ML, pero nos servirá pàra cruzar los datos con el resto de análisis que hagamos (_i.e._ `limma`, `DESEq2`, `edgeR`, etc).

Si el ANOVA trata de predecir la intensidad de una sonda a partir del factor `condición` (=`tratamiento`) y calcula el p-valor de la diferencia de medias de cada sonda, el análisis en ML tiene el enfoque contrario: A partir de las intensidades de todas las sondas, predecir la clase (=condición) a la que pertenece la instancia.

<br>

***

# Carga de datos y librerías



```{r instalacion caret y dependencias, eval = F}
# Instalación caret en R 3.6:
install.packages("caret")

# Paquete ff versión 2.2.0: (en el portatil la 2.2.14 funciona, en el sobremesa no)
install.packages("https://cran.r-project.org/src/contrib/Archive/ff/ff_2.2-0.tar.gz", 
                 repos=NULL, type = "source")

# Paquete RSQLite versión 2.1.4:
install.packages("https://cran.r-project.org/src/contrib/Archive/RSQLite/RSQLite_2.1.4.tar.gz",
                 repos=NULL, type = "source")
```


<br>

Comenzamos cargando `oligo` y paquetes accesorios:

```{r carga librerias, message = F}
# Cargamos librerías
library(caret)
library(Boruta)

library(partykit)
library(pROC)
library(MLmetrics)
library(partykit)
```

<br>


```{r}
intensidades_normalizadas_df <- readRDS("./intensidades_normalizadas_df.rds")

head(intensidades_normalizadas_df)
dim(intensidades_normalizadas_df)
# La última columna es la clase
```




<br>

***

# Preprocesado

Antes de aplicar los algoritmos de ML, necesitamos preprocesar el dataset.


<br>

## Imputación de valores NA

Como hemos generado nosotros mismos el dataset, sabemos que carece de valores NA, por lo que no hay que imputar nada.


<br>

## Formato de variables

Como vimos antes, todas las variables salvo la clase están en formato `numeric`. Por si acaso, volvemos a comprobar que R reconozca bien la clase y sus niveles.

```{r}
class(intensidades_normalizadas_df)
levels(intensidades_normalizadas_df$condicion)
```


<br>

## Escalado


Escalaríamos los datos si tuviesemos variables recogidas en distintas unidades (por ejemplo, algunas en metros, otras en kilometros...), pero al estar trabajando con arrays, no es necesario (todas las sondas se miden con las mismas unidades... ¿lumens?)


<br>

## Normalizado

Normalizamos previamente el dataset con `oligo` (algoritmo `RMA`) antes de cargarlo aquí, por lo que no es necesario.


<br>

## Variables redundantes (correlacionadas)


A cotinuación eliminamos las variables numéricas altamente correlacionadas con el metodo `findCorrelation` del paquete `caret`. Para ello necesitamos crear una __matriz de correlaciones__ que contenga exclusivamente las variables predictoras numéricas del dataset, por lo que seleccionaremos todas menos al última columa (clase)

```{r}
R <- cor(intensidades_normalizadas_df[,1:dim(intensidades_normalizadas_df)[2]-1])
caret::findCorrelation(
  R,
  cutoff = 0.75,
  verbose = TRUE,
  names = TRUE)
```

```{r, eval = F}
memory.limit(size = 2500)
memory.limit()
?gc()
gc()
```








<br>

Si tenemos cuenta en la página web de ThermoFisher, podemos usar el centro de análisis NetAffx para obtener más información sobre dichos clusters. Por ejemplo, si nos fijamos en el segundo _transcription cluster_, [TC0300011139.hg.1](https://www.affymetrix.com/analysis/netaffx/exon/hta_transcript.affx?pk=778:TC0300011139.hg.1), vemos que las sondas de este cluster detectan la presencia/ausencia de expresión del pseudogen RNA5SP132 (identificador [Ensembl:ENSG00000201595](http://www.ensembl.org/Homo_sapiens/Gene/Summary?g=ENSG00000201595;r=3:51694465-51694582;t=ENST00000364725)). 


```{r, echo = F, eval = F}
which(transcription_clusters == "TC1300007722.hg.1") # Devuelve 6 de 6 sondas

which(transcription_clusters == "TC0300011139.hg.1") # Devuelve 10 de 12 sondas

which(transcription_clusters == "TC1600006939.hg.1") # Devuelve 6 de 8 sondas

which(transcription_clusters == "TC0100018028.hg.1") # Devuelve 10 de 12 sondas

which(transcription_clusters == "TC0500010071.hg.1") # Devuelve 10 de 12 sondas

which(transcription_clusters == "TC1900010290.hg.1") # Devuelve 10 de 16 sondas
```



<br>

Además, el paquete `Biobase` incluye también numerosas funciones que se pueden ejecutar sobre los objetos de tipo `HTAFeatureSet` para obtener informacion contenida en el mismo, tales como abstracts, anotaciones, ...etc.

```{r}
# Anotación usada para nuestro objeto `HTAFeatureSet`
Biobase::annotation(datos_crudos_microarrays)

# Acceder a los datos del experimento del objeto `HTAFeatureSet` (en nuestro
# caso no está anotado)
Biobase::experimentData(datos_crudos_microarrays)
```


<br>

En relación a lo dicho en el párrafo anterior, las gráficas que generemos a lo largo del protocolo de análisis pueden usar información ubicada en el bolsillo `datos_crudos_microarrays@phenoData@data`, por lo que podemos añadir metadatos de interés con el comando `pData()` de `Biobase` tal que así:

```{r}
# Renombramos la columna "index" a "muestra"
colnames(pData(datos_crudos_microarrays)) <- "muestra"

# Añadimos el factor "Condición" a los metadatos de nuestro estudio
pData(datos_crudos_microarrays)$condicion <- as.factor(rep(c("Control", "Genisteina"), times = 4))

# Visualizamos los metadatos
pData(datos_crudos_microarrays)
```

<br>

***


# Métricas de calidad

## Efecto lote

Para analizar el efecto lote, podemos usar las fechas en las que se secuenciaron los microarrays. El comando `get.celfile.dates()` del paquete `affyio` devuelve la fecha de dicho proceso.

```{r}
affyio::get.celfile.dates(ruta_completa_archivos_secuenciado)
```
Vemos que los microarrays se secuenciaron el mismo día. Adicionalmente, el programa `GeneChip Command Console 6.0` de ThermoFisher (compañía propietaria de Affymetrix) aportó la hora del secuenciado, el cual duró 6 horas en total (11AM-5PM).

En vista de que el secuenciado se realizó en un sólo lote (el mismo día y en horas consecutivas), concluimos que la probabilidad de observar varianza debida al ruido técnico del efecto lote es mínima.


<br>

## Análisis QC

El programa `TAC 4.0.2`, propiedad también de ThermoFisher, muestra un resumen muy claro de las métricas de calidad de los microarrays.

![](../imagenes adjuntas/QC TAC.png)

Según la documentación del programa, un valor de `pos vs neg auc` > 0.7 es un buen primer cribado de calidad. Además de presentar un AUC > 0.7, el resto de controles han salido bien, por lo que podemos confiar en la calidad del secuenciado de los presentes microarrays.


En R, el paquete `oligo` parece no poder sacar dichas métricas en microarrays de tipo _Clariom_, puesto que al ser nuevos, no llevan asociados archivos `.CDF`. Quizás `limma` o `DESeq2` puedan tratar dichos microchips.



<br>

***

# Preprocesado de los microarrays: RMA


Antes de analizar los microarrays, necesitamos preprocesar las señales de las sondas para corregir el ruido técnico (problema común en los microarrays) y agrupar la información de las sondas que mapeen para un mismo gen (_summarization_).

Para preprocesar y normalizar datos de microarrays, se suelen emplear el algoritmo `RMA` o derivados (_i.e._ `GCRMA` o `SST-RMA`). En nuestro caso vamos a usar el algoritmo `RMA`, implementado en `oligo`. Este algoritmo consta de 3 pasos:

* __Background subtraction__. De acuerdo a la [documentación](http://bioconductor.org/packages/release/bioc/vignettes/oligo/inst/doc/oug.pdf) de `oligo`, el método de _background substraction_ implementado en RMA trata las sondas PM (_Perfect Match_, más informacion en [Flight _et al._](http://rmflight.github.io/affyMM/)) como una convolución de ruido y señal verdadera.

* __Quantile normalization__. Paso necesario para dotar de igual valor a los genes estudiados, independientemente de su nivel de expresión constitutivo (este paso evita, por ejemplo, que genes expresados de manera constitutiva pero poco interesantes para el estudio estén sobrerrepresentados en análisis posteriores con respecto de genes más relevantes, pero de menor expresión basal como son los genes codificantes de factores de transcripcion). El método de normalizado implementado en `oligo` es `quantile`.

* __Summarization__. Pasamos de analizar intensidades de sondas a niveles de expresión de genes. `oligo` realiza este paso mediante el método `medianpolish`.


Para más información sobre la implementación de estos pasos en oligo, por favor consulte la documentación de los comandos `rma`, `backgroundCorrectionMethods()` y sucedáneos.



<br>

En `oligo`, el comando `rma` nos devuelve un objeto de tipo `ExpressionSet` (similar al objeto `datos_crudos_microarrays`) con los datos preprocesados en el bolsillo `eSet_normalizado@assayData$exprs`. Procedemos al RMA:

```{r}
eSet_normalizado <- oligo::rma(object = datos_crudos_microarrays,
                                 background = T, normalize = T)

head(eSet_normalizado@assayData$exprs)[,1:4]
```

<br>

## Comprobación del normalizado: Boxplots

Podemos comparar los datos antes y después del normalizado y control de ruido técnico. Observamos que las intensidades medianas y los cuartiles 25-75 son idénticos entre todos los microarrays tras el normalizado, cosa que no era cierta en los datos crudos:

```{r}
par(mfcol = c(1,2))

boxplot(datos_crudos_microarrays, "all", 
        main = "Antes", col = rainbow(8), 
        ylab = "intensidad sondas (log2)")

boxplot(eSet_normalizado, main = "Después",
        col = rainbow(8), ylab = "intensidad sondas (log2)")
```


<br>

***

# Análisis DEG

De acuerdo a [McDermaid _et al._(2019)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6954399/), podría usar para DGE análisis edgeR, Cutdiff/Cutdiff2, limma, DESeq2.. etc

<br>


## Separación de las muestras: PCA y t-SNE

Con los datos ya normalizados, podemos graficar los microarrays estudiados en un espacio de dimensionalidad reducida. La separación de los microarrays en dicho espacio nos dará una idea general de si existen genes diferencialmente expresados entre las condiciones estudiadas.

Para el PCA, podemos usar las utilidades del paquete `FactoMineR` tal que así:

```{r}
# Creamos un dataframe de intensidades procesable por el PCA de 
# dimensiones instancias x variables
intensidades_normalizadas <- t(exprs(eSet_normalizado))
intensidades_normalizadas_df <- as.data.frame(intensidades_normalizadas)

# Añadimos al dataframe el factor "condicion"
intensidades_normalizadas_df$condicion <- pData(eSet_normalizado)$condicion

# Computamos las 3 primeras componentes principales
pca_microarrays <- PCA(intensidades_normalizadas_df, graph = F, 
                       axes = c(1:3), quali.sup = 138746)

# Graficamos las 2 primeras componentes principales
plot.PCA(pca_microarrays, choix = "ind", habillage = 138746)
```

```{r, eval = F}
# Para otros análisis
saveRDS(intensidades_normalizadas_df, file = "intensidades_normalizadas_df.rds")
```



```{r, eval = F}
# Graficamos las 3 primeras componentes principales
plot3d(pca_microarrays$ind$coord[,1:3], type = "s", 
       col = c(rep(c("black", "red"), times = 4)))
```


![Puntos negros: control; puntos rojos: tratados con genisteína](../imagenes adjuntas/PCA 3D.png)


<br>

<br>

y para el t-SNE:

```{r}
normalizado_tsne <- normalize_input(intensidades_normalizadas)
tsne_microarrays <- Rtsne(normalizado_tsne, dims = 3, perplexity = 2)

# Leyenda: Control negro, Genisteína rojo
plot(tsne_microarrays$Y, col = c("black", "red"))
```

```{r, eval = F}
plot3d(tsne_microarrays$Y[,1:3], type = "s", 
       col = c(rep(c("black", "red"), times = 4)))
```


<br>

<br>

y el UMAP:

```{r}
library("uwot")
umap_microarrays <- uwot::umap(intensidades_normalizadas, n_neighbors = 3, 
                               n_components = 3)

# Leyenda: Control negro, Genisteína rojo
plot(umap_microarrays, col = c("black", "red"))
```

```{r, eval = F}
# Graficamos el UMAP en 3D
plot3d(umap_microarrays, type = "s", 
       col = c(rep(c("black", "red"), times = 4)))

```


<br>


En resumen, sólo el PCA 3D es informativo de la posible distribución de las muestras. El t-SNE y el UMAP en 3D no son concluyentes (los datos parecen mezclarse).



<br>

## Análisis cualitativo: MA Plots

Para visualizar si hay genes diferencialmente expresados, podemos emplear el comando `MAplot` del paquete `oligo`. Los gráficos MA muestran en el eje X la intensidad media de una sonda dada a lo largo de los microarrays estudiados, y en el eje Y se observa el log2(fold change) o logaritmo en base dos del ratio de sobre/infraexpresión del gen al que mapea dicha sonda. 

Los genes diferencialmente expresados se encontrarán lejos de la nube de puntos (log2(FC) > |1|), mientras que los genes que no varíen entre condiciones presentarán valores de log2(FC) cercano a 0. No obstante, el MA plot no devuelve p-valores, por lo que para asegurarnos de que los resultados son significativos, deberíamos recurrir a un Volcano plot, que combina el log2FC y los p-valores de los genes estudiados.

```{r}
par(mfrow=c(2,2))

oligo::MAplot(eSet_normalizado, refSamples = c(1,3,5,7), which = c(2,4,6,8), main = "vs grupo Control")
```



<br>


## limma


Identification of DE genes is not done by the affy nor the oligo package but by the limma package. Limma uses the output of the rma() method (data.rma) as input. Since the output of the rma() method is the same in the affy and in the oligo package, limma works well with both packages. This means that all following code is valid for all normalized Affymetrix data regardless of the package that was used for normalization




First of all you need to tell limma which samples are replicates and which samples belong to different groups by providing this information in the phenoData slot of the AffyBatch/FeatureSet. To this end, we add a second column with sample annotation describing the source of each sample. We will give this new column a name. 


```{r}
# Creamos el diseño del t-test
diseno = model.matrix(~ 0 + eSet_normalizado$condicion)
colnames(diseno) = c("Control","Genisteina")


library("limma")
# Generamos modelo lineal
data.fit = lmFit(t(intensidades_normalizadas), diseno)

data.fit$coefficients[1:10,]




contrast.matrix = makeContrasts(Genisteina-Control, levels = diseno)

data.fit.con = contrasts.fit(data.fit, contrast.matrix)


data.fit.eb = eBayes(data.fit.con)


# Log2FC de genes:
data.fit.eb$coefficients[11600:11610,]

# p-valores de los t-tests moderados por eBayes
data.fit.eb$p.value[11600:11610,]

data.fit.eb$coefficients

# Genes en los cuadrantes superiores derecho e izquierdo son candidatos de genes diferencialmente expresados y estadísticamente significativos
volcanoplot(data.fit.eb, highlight = 10); abline(h = 1.301, v = c(-1,1))
```

```{r}
tab = topTable(data.fit.eb ,coef = 1 ,number = 200, adjust.method ="BH", sort.by = "p")
head(tab)
```



<br>

***

# SECCIÓN EXPERIMENTAL!!!!!!!!


## Diagramas Venn


https://www.datanovia.com/en/blog/venn-diagram-with-r-or-rstudio-a-million-ways/
paquetes ggvenn o ggVennDiagram

***

<br>

De acuerdo a [McDermaid _et al._(2019)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6954399/), podría usar para DGE análisis edgeR, Cutdiff/Cutdiff2, limma, DESeq2.. etc


# Bibliografía

* PlaceHolder



***

<br>


# sessionInfo()

```{r, echo = F}
sessionInfo()
```
